{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSY9X6VEJMvK",
        "outputId": "ec7d8230-d5f9-4501-8584-92cf33c9a510"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fire-tongue.txt', <http.client.HTTPMessage at 0x7bd2409e80a0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import urllib.request\n",
        "url = \"https://en.wikisource.org/wiki/Fire-Tongue/Chapter_1\"\n",
        "file_path = \"fire-tongue.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"fire-tongue.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "print(f\"Total number of characters: {len(raw_text)}\")\n",
        "print(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsX62xIAUWlP",
        "outputId": "c4fc96ed-1afc-40b0-9120-159f85db7f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 56911\n",
            "<!DOCTYPE html>\n",
            "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
            "<head>\n",
            "<meta charset=\"UTF-8\">\n",
            "<title>Fire-Tongue/Chapter 1 - Wikisource, the free online library</title>\n",
            "<script>(function(){var className=\"client-js\";var cookie=document.cookie.match(/(?:^|; )enwikisourcemwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\\w+$|[^\\w-]+/g,'')+'-clientpref-\\\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"99aa2999-7054-410a-8e5a-6e9c1811ac86\",\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Fire-Tongue/Chapter_1\",\"wgTitle\":\"Fire-Tongue/Chapter 1\",\"wgCurRevisionId\":10804536,\"wgRevisionId\":10804536,\"wgArticleId\":2118663,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\n",
            "\"wgCategories\":[\"Subpages\",\"PD-old-60-US\"],\"wgPageViewLanguage\":\"en\",\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Fire-Tongue/Chapter_1\",\"wgRelevantArticleId\":2118663,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgNoticeProject\":\"wikisource\",\"wgCiteReferencePreviewsActive\":true,\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":300,\"prpProofreadPageBookNamespaces\":[0,0,114],\"prpSourceIndexPage\":\"Index:Sax Rohmer - Fire Tongue.djvu\",\"wgEditSubmitButtonLabelPublish\":true,\"wgULSPosition\":\"interlanguage\",\"wgULSisCompactLinksEnabled\":false,\"wgVector2022LanguageInHeader\":false,\"wgULSisLanguageSelectorEmpty\":false,\n",
            "\"wgCheckUserClientHintsHeadersJsApi\":[\"brands\",\"architecture\",\"bitness\",\"fullVersionList\",\"mobile\",\"model\",\"platform\",\"platformVersion\"]};RLSTATE={\"ext.gadget.Site-styles\":\"ready\",\"ext.gadget.MoreMenu-local-pagestyles\":\"ready\",\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"oojs-ui-core.styles\":\"ready\",\"oojs-ui.styles.indicators\":\"ready\",\"mediawiki.widgets.styles\":\"ready\",\"oojs-ui-core.icons\":\"ready\",\"ext.wikisource.icons\":\"ready\",\"ext.proofreadpage.base\":\"ready\",\"ext.proofreadpage.article\":\"ready\",\"skins.vector.styles.legacy\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"codex-search-styles\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.wikimediaBadges\":\"ready\"};RLPAGEMODULES=[\"ext.wikisource.download\",\"site\",\"mediawiki.page.ready\",\"skins.vector.legacy.js\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\n",
            "\"ext.gadget.charinsert\",\"ext.gadget.Easy_LST\",\"ext.gadget.Fill_Index\",\"ext.gadget.IndexFormTools\",\"ext.gadget.Site\",\"ext.gadget.PageNumbers\",\"ext.gadget.MoreMenu-local\",\"ext.gadget.PurgeTab\",\"ext.gadget.interwiki-transclusion\",\"ext.gadget.extra-toolbar-buttons\",\"ext.urlShortener.toolbar\",\"ext.centralauth.centralautologin\",\"mmv.bootstrap\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.echo.centralauth\",\"ext.eventLogging\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.uls.interface\",\"ext.checkUser.clientHints\"];</script>\n",
            "<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return[\"user.options@12s5i\",function($,jQuery,require,module){mw.user.tokens.set({\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});\n",
            "}];});});</script>\n",
            "<link rel=\"stylesheet\" href=\"/w/load.php?lang=en&amp;modules=codex-search-styles%7Cext.proofreadpage.article%2Cbase%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cext.wikisource.icons%7Cmediawiki.widgets.styles%7Coojs-ui-core.icons%2Cstyles%7Coojs-ui.styles.indicators%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector\">\n",
            "<script async=\"\" src=\"/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector\"></script>\n",
            "<meta name=\"ResourceLoaderDynamicStyles\" content=\"\">\n",
            "<link rel=\"stylesheet\" href=\"/w/load.php?lang=en&amp;modules=ext.gadget.MoreMenu-local-pagestyles%2CSite-styles&amp;only=styles&amp;skin=vector\">\n",
            "<meta name=\"generator\" content=\"MediaWiki 1.44.0-wmf.5\">\n",
            "<meta name=\"referrer\" content=\"origin\">\n",
            "<meta name=\"referrer\" content=\"origin-when-cross-origin\">\n",
            "<meta name=\"robots\" content=\"max-image-preview:standard\">\n",
            "<meta name=\"format-detection\" content=\"telephone=no\">\n",
            "<meta name=\"viewport\" content=\"width=1120\">\n",
            "<meta property=\"og:title\" content=\"Fire-Tongue/Chapter 1 - Wikisource, the free online library\">\n",
            "<meta property=\"og:type\" content=\"website\">\n",
            "<link rel=\"preconnect\" href=\"//upload.wikimedia.org\">\n",
            "<link rel=\"alternate\" media=\"only screen and (max-width: 640px)\" href=\"//en.m.wikisource.org/wiki/Fire-Tongue/Chapter_1\">\n",
            "<link rel=\"alternate\" type=\"application/x-wiki\" title=\"Edit\" href=\"/w/index.php?title=Fire-Tongue/Chapter_1&amp;action=edit\">\n",
            "<link rel=\"icon\" href=\"/static/favicon/wikisource.ico\">\n",
            "<link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/w/rest.php/v1/search\" title=\"Wikisource (en)\">\n",
            "<link rel=\"EditURI\" type=\"application/rsd+xml\" href=\"//en.wikisource.org/w/api.php?action=rsd\">\n",
            "<link rel=\"canonical\" href=\"https://en.wikisource.org/wiki/Fire-Tongue/Chapter_1\">\n",
            "<link rel=\"license\" href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n",
            "<link rel=\"alternate\" type=\"application/atom+xml\" title=\"Wikisource Atom feed\" href=\"/w/index.php?title=Special:RecentChanges&amp;feed=atom\">\n",
            "<link rel=\"dns-prefetch\" href=\"//meta.wikimedia.org\" />\n",
            "<link rel=\"dns-prefetch\" href=\"//login.wikimedia.org\">\n",
            "</head>\n",
            "<body class=\"skin-vector-legacy mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Fire-Tongue_Chapter_1 rootpage-Fire-Tongue skin-vector action-view\"><div id=\"mw-page-base\" class=\"noprint\"></div>\n",
            "<div id=\"mw-head-base\" class=\"noprint\"></div>\n",
            "<div id=\"content\" class=\"mw-body\" role=\"main\">\n",
            "\t<a id=\"top\"></a>\n",
            "\t<div id=\"siteNotice\"><!-- CentralNotice --></div>\n",
            "\t<div class=\"mw-indicators\">\n",
            "\t<div id=\"mw-indicator-~ext-wikisource-download\" class=\"mw-indicator\"><span id='ooui-php-1' class='ext-wikisource-download-button oo-ui-widget oo-ui-widget-enabled oo-ui-buttonElement oo-ui-buttonElement-framed oo-ui-labelElement oo-ui-flaggedElement-primary oo-ui-flaggedElement-progressive oo-ui-buttonWidget' data-ooui='{\"_\":\"OO.ui.ButtonWidget\",\"href\":\"https:\\/\\/ws-export.wmcloud.org\\/?format=epub&amp;lang=en&amp;page=Fire-Tongue%2FChapter_1\",\"rel\":[\"nofollow\"],\"label\":\"Download\",\"title\":\"Download an EPUB version of this work\",\"flags\":[\"primary\",\"progressive\"],\"data\":{\"wsExportUrl\":\"https:\\/\\/ws-export.wmcloud.org\"},\"classes\":[\"ext-wikisource-download-button\"]}'><a role='button' title='Download an EPUB version of this work' tabindex='0' href='https://ws-export.wmcloud.org/?format=epub&amp;lang=en&amp;page=Fire-Tongue%2FChapter_1' rel='nofollow' class='oo-ui-buttonElement-button'><span class='oo-ui-iconElement-icon oo-ui-iconElement-noIcon oo-ui-image-invert'></span><span class='oo-ui-labelElement-label'>Download</span><span class='oo-ui-indicatorElement-indicator oo-ui-indicatorElement-noIndicator oo-ui-image-invert'></span></a></span></div>\n",
            "\t</div>\n",
            "\t<h1 id=\"firstHeading\" class=\"firstHeading mw-first-heading\"><span class=\"mw-page-title-main\">Fire-Tongue/Chapter 1</span></h1>\n",
            "\t<div id=\"bodyContent\" class=\"vector-body\">\n",
            "\t\t<div id=\"siteSub\" class=\"noprint\">From Wikisource</div>\n",
            "\t\t<div id=\"contentSub\"><div id=\"mw-content-subtitle\"><div class=\"subpages\">&lt; <bdi dir=\"ltr\"><a href=\"/wiki/Fire-Tongue\" title=\"Fire-Tongue\">Fire-Tongue</a></bdi></div><table class=\"pr_quality\" title=\"12 validated pages, 0 only proofread pages and 0 not proofread pages\"><tr><td class=\"quality4\" style=\"width: 100%;\"></td><td class=\"quality3\" style=\"width: 0%;\"></td><td class=\"quality2\" style=\"width: 0%;\"></td><td class=\"quality1\" style=\"width: 0%;\"></td><td class=\"quality0\" style=\"width: 0%;\"></td><td class=\"qualitye\" style=\"width: 0%;\"></td></tr></table></div></div>\n",
            "\t\t<div id=\"contentSub2\"></div>\n",
            "\t\t\n",
            "\t\t<div id=\"jump-to-nav\"></div>\n",
            "\t\t<a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>\n",
            "\t\t<a class=\"mw-jump-link\" href=\"#searchInput\">Jump to search</a>\n",
            "\t\t<div id=\"mw-content-text\" class=\"mw-body-content\"><div class=\"mw-content-ltr mw-parser-output\" lang=\"en\" dir=\"ltr\"><div class=\"ws-noexport\"><style data-mw-deduplicate=\"TemplateStyles:r14688030\">.mw-parser-output .wst-header .wst-header-mainblock{border:1px solid #ACA;background-color:#E6F2E6;color:#202122}.mw-parser-output .wst-header .wst-header-notes{border-bottom:1px solid #A0A0A0;background-color:#FAFAFF;color:#202122}.mw-parser-output .wst-header .contributor-text{font-style:italic}.mw-parser-output .wst-header #header-title-text{font-weight:bold}.mw-parser-output .wst-header #ws-data{display:none}.mw-parser-output .wst-header #ws-data.ws-data-show{display:block}</style></div><style data-mw-deduplicate=\"TemplateStyles:r14182871\">.mw-parser-output .wst-header-mainblock{margin:4px auto 4px auto;padding:0 3px;display:flex;align-items:center}.mw-parser-output .wst-header-back,.mw-parser-output .wst-header-forward{display:flex;flex:1 4 100%;min-width:min-content;align-items:center;font-size:.9em}.mw-parser-output .wst-header-nav-empty{visibility:hidden}.mw-parser-output .wst-header-back{justify-content:flex-start;text-align:left}.mw-parser-output .wst-header-central-cell{flex:4 1 100%;max-width:max-content;text-align:center}.mw-parser-output .wst-header-forward{justify-content:flex-end;text-align:right}@media(max-width:768px){.mw-parser-output .wst-header-mainblock{flex-wrap:wrap}.mw-parser-output .wst-header-central-cell{flex:0 0 100%;order:-2;width:auto}.mw-parser-output .wst-header-back,.mw-parser-output .wst-header-forward{width:auto}}.mw-parser-output .wst-header-notes{display:inline-block;border-collapse:collapse;border-spacing:0;empty-cells:hide;font-size:.9em;line-height:1.4;margin:0 auto 4px auto;width:100%}.mw-parser-output .wst-header-left{float:left}</style><div class=\"ws-header wst-header-structure wst-unknown wst-header ws-header ws-noexport noprint dynlayout-exempt\"><div class=\"wst-header-mainblock wst-unknown-mainblock headertemplate\"><div class=\"wst-header-back searchaux wst-unknown-back\"><div class=\"wst-header-back-arrow\">←</div><div class=\"wst-header-back-link\"><a href=\"/wiki/Fire-Tongue\" title=\"Fire-Tongue\">Front Matter</a></div></div><div class=\"wst-header-central-cell wst-unknown-central-cell\"><span class=\"wst-header-title wst-unknown-title\"><span id=\"header-title-text\"><a href=\"/wiki/Fire-Tongue\" title=\"Fire-Tongue\">Fire-Tongue</a></span><br id=\"header-title-break\" /><span class=\"contributor-text\">by&#160;<span class=\"fn\"><a href=\"/wiki/Author:Sax_Rohmer\" class=\"mw-redirect\" title=\"Author:Sax Rohmer\">Sax Rohmer</a></span></span><div class=\"header-section-text\">Chapter I</div></span></div><div class=\"wst-header-forward searchaux wst-unknown-forward\"><div class=\"wst-header-forward-link\"><a href=\"/wiki/Fire-Tongue/Chapter_2\" title=\"Fire-Tongue/Chapter 2\">Chapter II</a></div><div class=\"wst-header-forward-arrow\">→</div></div></div><div class=\"ws-noexport\" id=\"ws-data\" style=\"speak:none\"><span id=\"ws-article-id\">2118663</span><span id=\"ws-title\"><a href=\"/wiki/Fire-Tongue\" title=\"Fire-Tongue\">Fire-Tongue</a> — Chapter I</span><span id=\"ws-author\">Sax Rohmer</span></div></div>\n",
            "<div class=\"wst-dhr\" style=\"visibility:hidden; line-height:4;\">&#160;</div>\n",
            "<p><span style=\"display:none\" id=\"dynamic_layout_overrider\">Layout 2</span>\n",
            "</p>\n",
            "<div class=\"prp-pages-output\" lang=\"en\">\n",
            "<span><span class=\"pagenum ws-pagenum\" id=\"1\" data-page-number=\"1\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/17\" data-page-index=\"17\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/17\"><span id=\"pageindex_17\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span><style data-mw-deduplicate=\"TemplateStyles:r13089542\">.mw-parser-output .wst-center{text-align:center;display:table;margin:0 auto 0 auto}.mw-parser-output .wst-center.wst-center-nomargin>p{margin-bottom:0}</style><div class=\"wst-center tiInherit wst-center-nomargin\">\n",
            "<p><span style=\"font-size:182%;\">FIRE-TONGUE</span>\n",
            "</p>\n",
            "<div class=\"wst-dhr\" style=\"visibility:hidden; line-height:2;\">&#160;</div>\n",
            "<p><span style=\"font-size: 120%;\">CHAPTER I</span>\n",
            "</p>\n",
            "<div class=\"wst-dhr\" style=\"visibility:hidden; line-height:100%;\">&#160;</div> \n",
            "<p><span style=\"font-size: 83%;\">A CLIENT FOR PAUL HARLEY</span>\n",
            "</p>\n",
            "</div>\n",
            "<div class=\"wst-dhr\" style=\"visibility:hidden; line-height:100%;\">&#160;</div> \n",
            "<p><style data-mw-deduplicate=\"TemplateStyles:r13425350\">.mw-parser-output .dropinitial{float:left;text-indent:0}.mw-parser-output .dropinitial .dropinitial-fl{float:left;position:relative;vertical-align:top;line-height:1}.mw-parser-output .dropinitial .dropinitial-mid .dropinitial-initial{float:left;line-height:1em;text-indent:0;font-size:3em;margin:0 0.1em 0 0}</style><span class=\"dropinitial drop-initial-no-image\"><span class=\"dropinitial-mid\"><span class=\"dropinitial-initial\">S</span></span></span>OME of Paul Harley's most interesting cases were brought to his notice in an almost accidental way. Although he closed his office in Chancery Lane sharply at the hour of six, the hour of six by no means marked the end of his business day. His work was practically ceaseless. But even in times of leisure, at the club or theatre, fate would sometimes cast in his path the first slender thread which was ultimately to lead him into some unsuspected labyrinth, perhaps in the underworld of London, perhaps in a city of the Far East. \n",
            "</p><p>His investigation of the case of the man with the shaven skull afforded an instance of this, and even more notable was his first meeting with Major Jack Ragstaff of the Cavalry Club, a meeting which took place after the office had been closed, but which led to the unmasking of perhaps the most cunning murderer in the annals of crime. \n",
            "</p><p>One summer's evening when the little clock upon&#32;<span><span class=\"pagenum ws-pagenum\" id=\"2\" data-page-number=\"2\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/18\" data-page-index=\"18\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/18\"><span id=\"pageindex_18\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>his table was rapidly approaching the much-desired hour, Harley lay back in his chair and stared meditatively across his private office in the direction of a large and very handsome Burmese cabinet, which seemed strangely out of place amid the filing drawers, bookshelves, and other usual impedimenta of a professional man. A peculiarly uninteresting week was drawing to a close, and he was wondering if this betokened a decreased activity in the higher criminal circles, or whether it was merely one of those usual quiescent periods which characterize every form of warfare. \n",
            "</p><p>Paul Harley, although the fact was unknown to the general public, occupied something of the position of an unofficial field marshal of the forces arrayed against evildoers. Throughout the war he had undertaken confidential work of the highest importance, especially in regard to the Near East, with which he was intimately acquainted. A member of the English bar, and the last court of appeal to which Home Office and Foreign Office alike came in troubled times, the brass plate upon the door of his unassuming premises in Chancery Lane conveyed little or nothing to the uninitiated. \n",
            "</p><p>The man himself, with his tropical bronze and air of eager vitality, must have told the most careless observer that he stood in the presence of an extraordinary personality. He was slightly gray at the temples in these days, but young in mind and body,&#32;<span><span class=\"pagenum ws-pagenum\" id=\"3\" data-page-number=\"3\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/19\" data-page-index=\"19\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/19\"><span id=\"pageindex_19\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>physically fit, and possessed of an intellectual keenness which had forced recognition from two hemispheres. His office was part of an old city residence, and his chambers adjoined his workroom, so that now, noting that his table clock registered the hour of six, he pressed a bell which summoned Innes, his confidential secretary. \n",
            "</p><p>\"Well, Innes,\" said Harley, looking around, \"another uneventful day.\" \n",
            "</p><p>\"Very uneventful, Mr. Harley. About a month of this and you will have to resume practice at the bar.\" \n",
            "</p><p>Paul Harley laughed. \n",
            "</p><p>\"Not a bit likely, Innes,\" he replied. \"No more briefs for me. I shall retire to Norfolk and devote my declining years to fishing.\" \n",
            "</p><p>\"I don't know that fishing would entirely satisfy me,\" said Innes. \n",
            "</p><p>\"It would more than satisfy <i>me</i>\" returned Harley. \"But every man to his own ambition. Well, there is no occasion to wait; you might as well get along. But what's that you've got in your hand?\" \n",
            "</p><p>\"Well,\" replied Innes, laying a card upon the table, \"I was just coming in with it when you rang.\" \n",
            "</p><p>Paul Harley glanced at the card. \n",
            "</p><p>\"Sir Charles Abingdon,\" he read aloud, staring reflectively at his secretary. \"That is the <a href=\"https://en.wiktionary.org/wiki/osteologist\" class=\"extiw\" title=\"wikt:osteologist\">osteologist</a>?\" \n",
            "</p><p>\"Yes,\" answered Innes, \"but I fancy he has retired from practice.\" \n",
            "</p>\n",
            "<div class=\"&#95;_nop wst-nop\"></div>\n",
            "<p>&#32;<span><span class=\"pagenum ws-pagenum\" id=\"4\" data-page-number=\"4\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/20\" data-page-index=\"20\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/20\"><span id=\"pageindex_20\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>\"Ah,\" murmured Harley, \"I wonder what he wants. I suppose I had better see him, as I fancy that he and I met casually some years ago in India. Ask him to come in, will you?\"\n",
            "</p><p>Innes retiring, there presently entered a distinguished-looking, elderly gentleman upon whose florid face rested an expression not unlike that of embarrassment. \n",
            "</p><p>\"Mr. Harley,\" he began, \"I feel somewhat ill at ease in encroaching upon your time, for I am by no means sure that my case comes within your particular province.\" \n",
            "</p><p>\"Sit down, Sir Charles,\" said Harley with quiet geniality. \"Officially, my working day is ended; but if nothing comes of your visit beyond a chat it will have been very welcome. Calcutta, was it not, where we last met?\" \n",
            "</p><p>\"It was,\" replied Sir Charles, placing his hat and cane upon the table and sitting down rather wearily in a big leather armchair which Harley had pushed forward. \"If I presume upon so slight an acquaintance, I am sorry, but I must confess that only the fact of having met you socially encouraged me to make this visit.\" \n",
            "</p><p>He raised his eyes to Harley's face and gazed at him with that peculiarly searching look which belongs to members of his profession; but mingled with it was an expression of almost pathetic appeal, of appeal for understanding, for sympathy of some kind. \n",
            "</p>\n",
            "<div class=\"&#95;_nop wst-nop\"></div>\n",
            "<p>&#32;<span><span class=\"pagenum ws-pagenum\" id=\"5\" data-page-number=\"5\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/21\" data-page-index=\"21\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/21\"><span id=\"pageindex_21\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>\"Go on, Sir Charles,\" said Harley. He pushed forward a box of cigars. \"Will you smoke?\"\n",
            "</p><p>\"Thanks, no,\" was the answer. \n",
            "</p><p>Sir Charles evidently was oppressed by some secret trouble, thus Harley mused silently, as, taking out a tin of tobacco from a cabinet beside him, he began in leisurely manner to load a briar. In this he desired to convey that he treated the visit as that of a friend, and also, since business was over, that Sir Charles might without scruple speak at length and at leisure of whatever matters had brought him there. \n",
            "</p><p>\"Very well, then,\" began the surgeon; \"I am painfully conscious that the facts which I am in a position to lay before you are very scanty and unsatisfactory.\" \n",
            "</p><p>Paul Harley nodded encouragingly. \n",
            "</p><p>\"If this were not so,\" he explained, \"you would have no occasion to apply to me, Sir Charles. It is my business to look for facts. Naturally, I do not expect my clients to supply them.\" \n",
            "</p><p>Sir Charles slowly nodded his head, and seemed in some measure to recover confidence. \n",
            "</p><p>\"Briefly, then,\" he said, \"I believe my life is in danger.\" \n",
            "</p><p>\"You mean that there is someone who desires your death?\" \n",
            "</p><p>\"I do.\" \n",
            "</p><p>\"H'm,\" said Harley, replacing the tin in the &#32;<span><span class=\"pagenum ws-pagenum\" id=\"6\" data-page-number=\"6\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/22\" data-page-index=\"22\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/22\"><span id=\"pageindex_22\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>cupboard and striking a match. \"Even if the facts are scanty, no doubt you have fairly substantial grounds for such a suspicion?\" \n",
            "</p><p>\"I cannot say that they are substantial, Mr. Harley. They are rather more circumstantial. Frankly, I have forced myself to come here, and now that I have intruded upon your privacy, I realize my difficulties more keenly than ever.\"\n",
            "</p><p>The expression of embarrassment upon the speaker's face had grown intense; and now he paused, bending forward in his chair. He seemed in his glance to appeal for patience on the part of his hearer, and Harley, lighting his pipe, nodded in understanding fashion. He was the last man in the world to jump to conclusions. He had learned by bitter experience that lightly to dismiss such cases as this of Sir Charles as coming within the province of delusion, was sometimes tantamount to refusing aid to a man in deadly peril. \n",
            "</p><p>\"You are naturally anxious for the particulars,\" Sir Charles presently resumed. \"They bear, I regret to say, a close resemblance to the symptoms of a well-known form of hallucination. In short, with one exception, they may practically all be classed under the head of surveillance.\" \n",
            "</p><p>\"Surveillance,\" said Paul Harley. \"You mean that you are more or less constantly followed?\" \n",
            "</p><p>\"I do.\"\n",
            "</p><p>\"And what is your impression of this follower?\"\n",
            "</p>\n",
            "<div class=\"&#95;_nop wst-nop\"></div>\n",
            "<p>&#32;<span><span class=\"pagenum ws-pagenum\" id=\"7\" data-page-number=\"7\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/23\" data-page-index=\"23\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/23\"><span id=\"pageindex_23\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>\"A very hazy one. To-night, as I came to your office, I have every reason to believe that someone followed me in a taxicab.\" \n",
            "</p><p>\"You came in a car?\" \n",
            "</p><p>\"I did.\" \n",
            "</p><p>\"And a cab followed you the whole way?\" \n",
            "</p><p>\"Practically the whole way, except that as my chauffeur turned into Chancery Lane, the cab stopped at the corner of Fleet Street.\" \n",
            "</p><p>\"Your idea is that your pursuer followed on foot from this point?\"\n",
            "</p><p>\"Such was my impression.\"\n",
            "</p><p>\"H'm, quite impossible. And is this sort of thing constant, Sir Charles?\"\n",
            "</p><p>\"It has been for some time past.\"\n",
            "</p><p>\"Anything else?\"\n",
            "</p><p>\"One very notable thing, Mr. Harley. I was actually assaulted less than a week ago within sight of my own house.\"\n",
            "</p><p>\"Indeed! Tell me of this.\" Paul Harley became aware of an awakening curiosity. Sir Charles Abingdon was not the type of man who is lightly intimidated.\n",
            "</p><p>\"I had been to visit a friend in the neighbourhood,\" Sir Charles continued, \"whom I am at present attending professionally, although I am actually retired. I was returning across the square, close to midnight, when, fortunately for myself, I detected the sound of light, pattering footsteps immediately&#32;<span><span class=\"pagenum ws-pagenum\" id=\"8\" data-page-number=\"8\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/24\" data-page-index=\"24\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/24\"><span id=\"pageindex_24\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>behind me. The place was quite deserted at that hour, and although I was so near home, the worst would have happened, I fear, if my sense of hearing had been less acute. I turned in the very instant that a man was about to spring upon me from behind. He was holding in his hand what looked like a large silk handkerchief. This encounter took place in the shadow of some trees, and beyond the fact that my assailant was a small man, I could form no impression of his identity.\"\n",
            "</p><p>\"What did you do?\"\n",
            "</p><p>\"I turned and struck out with my stick.\"\n",
            "</p><p>\"And then?\"\n",
            "</p><p>\"Then he made no attempt to contest the issue, but simply ran swiftly off, always keeping in the shadows of the trees.\"\n",
            "</p><p>\"Very strange,\" murmured Harley. \"Do you think he had meant to drug you?\" \n",
            "</p><p>\"Maybe,\" replied Sir Charles. \"The handkerchief was perhaps saturated with some drug, or he may even have designed to attempt to strangle me.\"\n",
            "</p><p>\"And you formed absolutely no impression of the man?\"\n",
            "</p><p>\"None whatever, Mr. Harley. When you see the spot at which the encounter took place, if you care to do so, you will recognize the difficulties. It is perfectly dark there after nightfall.\"\n",
            "</p><p>\"H'm,\" mused Harley. \"A very alarming occurrence, Sir Charles. It must have shaken you very&#32;<span><span class=\"pagenum ws-pagenum\" id=\"9\" data-page-number=\"9\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/25\" data-page-index=\"25\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/25\"><span id=\"pageindex_25\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>badly. But we must not overlook the possibility that this may have been an ordinary <a href=\"https://en.wiktionary.org/wiki/footpad\" class=\"extiw\" title=\"wikt:footpad\">footpad</a>.\" \n",
            "</p><p>\"His methods were scarcely those of a footpad,\" murmured Sir Charles. \n",
            "</p><p>\"I quite agree,\" said Harley. \"They were rather Oriental, if I may say so.\"\n",
            "</p><p>Sir Charles Abingdon started. \"Oriental!\" he whispered. \"Yes, you are right.\"\n",
            "</p><p>\"Does this suggest a train of thought?\" prompted Harley. \n",
            "</p><p>Sir Charles Abingdon cleared his throat nervously. \"It does, Mr. Harley,\" he admitted, \"but a very confusing train of thought. It leads me to a point which I must mention, but which concerns a very well-known man. Before I proceed I should like to make it clear that I do not believe for a moment that he is responsible for this unpleasant business.\"\n",
            "</p><p>Harley stared at him curiously. \"Nevertheless,\" he said, \"there must be some data in your possession which suggest to your mind that he has some connection with it.\"\n",
            "</p><p>\"There are, Mr. Harley, and I should be deeply indebted if you could visit my house this evening, when I could place this evidence, if evidence it may be called, before you. I find myself in so delicate a position. If you are free I should welcome your company at dinner.\"\n",
            "</p><p>Paul Harley seemed to be reflecting.\n",
            "</p><p>\"Of course, Sir Charles,\" he said, presently, \"your&#32;<span><span class=\"pagenum ws-pagenum\" id=\"10\" data-page-number=\"10\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/26\" data-page-index=\"26\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/26\"><span id=\"pageindex_26\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>statement is very interesting and curious, and I shall naturally make a point of going fully into the matter. But before proceeding further there are two questions I should like to ask you. The first is this: What is the name of the 'well-known' man to whom you refer? And the second: If not he then <i>whom</i> do you suspect of being behind all this?\"\n",
            "</p><p>Sir Charles's perplexity and embarrassment grew more and more marked.\n",
            "</p><p>\"The one matter is so hopelessly involved in the other,\" he finally replied, \"that although I came here prepared as I thought with a full statement of the case, I should welcome a further opportunity of rearranging the facts before imparting them to you. One thing, however, I have omitted to mention. It is, perhaps, of paramount importance. There was a robbery at my house less than a week ago.\"\n",
            "</p><p>\"What! A robbery! Tell me: what was stolen?\"\n",
            "</p><p>\"Nothing of the slightest value, Mr. Harley, to any one but myself—or so I should have supposed.\" The speaker coughed nervously. \"The thief had gained admittance to my private study, where there are several cases of Oriental jewellery and a number of pieces of valuable gold and silverware, all antique. At what hour he came, how he gained admittance, and how he retired, I cannot imagine. All the doors were locked as usual in the morning and nothing was disturbed.\"\n",
            "</p><p>\"I don't understand, then.\" \n",
            "</p>\n",
            "<div class=\"&#95;_nop wst-nop\"></div>\n",
            "<p>&#32;<span><span class=\"pagenum ws-pagenum\" id=\"11\" data-page-number=\"11\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/27\" data-page-index=\"27\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/27\"><span id=\"pageindex_27\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>\"I chanced to have occasion to open my bureau, which I invariably keep locked. Immediately—immediately—I perceived that my papers were disarranged. Close examination revealed the fact that a short manuscript in my own hand, which had been placed in one of the pigeonholes, was missing.\"\n",
            "</p><p>\"A manuscript,\" murmured Harley. \"Upon a technical subject?\"\n",
            "</p><p>\"Scarcely a technical subject, Mr. Harley. It was a brief account which I had vaguely contemplated publishing in one of the reviews, a brief account of a very extraordinary patient whom I once attended.\"\n",
            "</p><p>\"And had you written it recently?\"\n",
            "</p><p>\"No; some years ago. But I had recently added to it. I may say that it was my purpose still further to add to it, and with this object I had actually unlocked the bureau.\"\n",
            "</p><p>\"New facts respecting this patient had come into your possession?\"\n",
            "</p><p>\"They had.\"\n",
            "</p><p>\"Before the date of the attack upon you?\"\n",
            "</p><p>\"Before that date, yes.\"\n",
            "</p><p>\"And before surveillance of your movements began?\"\n",
            "</p><p>\"I believe so.\"\n",
            "</p><p>\"May I suggest that your patient and the 'well-known man' to whom you referred are one and the same?\" \n",
            "</p>\n",
            "<div class=\"&#95;_nop wst-nop\"></div>\n",
            "<p>&#32;<span><span class=\"pagenum ws-pagenum\" id=\"12\" data-page-number=\"12\" data-page-name=\"Page:Sax Rohmer - Fire Tongue.djvu/28\" data-page-index=\"28\" data-page-quality=\"4\" title=\"Page:Sax_Rohmer_-_Fire_Tongue.djvu/28\"><span id=\"pageindex_28\" class=\"pagenum-inner ws-noexport\">&#8203;</span></span></span>\"It is not so, Mr. Harley,\" returned Sir Charles in a tired voice. \"Nothing so simple. I realize more than ever that I must arrange my facts in some sort of historical order. Therefore I ask you again: will you dine with me to-night?\"\n",
            "</p><p>\"With pleasure,\" replied Harley, promptly. \"I have no other engagement.\" \n",
            "</p><p>That his ready acceptance had immensely relieved the troubled mind of Sir Charles was evident enough. His visitor stood up. \"I am not prone to sickly fancies, Mr. Harley,\" he said. \"But a conviction has been growing upon me for some time that I have incurred, how I cannot imagine, but that nevertheless I have incurred powerful enmity. I trust our evening's counsel may enable you, with your highly specialized faculties, to detect an explanation.\"\n",
            "</p><p>And it was instructive to note how fluently he spoke now that he found himself temporarily relieved of the necessity of confessing the source of his mysterious fears.\n",
            "</p>\n",
            "<div class=\"&#95;_nop wst-nop\"></div>\n",
            "<p>&#32;\n",
            "</p>\n",
            "</div>\n",
            "<style data-mw-deduplicate=\"TemplateStyles:r14318802\">.mw-parser-output .licenseContainer{box-sizing:border-box;margin-top:1em;margin-bottom:0.25em;clear:both;width:auto;page-break-before:always;break-before:page}.mw-parser-output .licenseContainer>div:first-child{display:table;border:2px solid #88A;border-collapse:collapse;border-spacing:0 0;empty-cells:hide;box-sizing:border-box;margin:0 auto 0 auto;width:100%;background-color:#F7F8FF;color:#202122}.mw-parser-output .licenseContainer>div:first-child>div:first-child{display:table-row-group}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child{display:table-row}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div{display:table-cell;padding:5px;vertical-align:middle;width:auto}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:first-child{text-align:left}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(2){text-align:center}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(2)>div{width:100%}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(2)>div:first-child{display:block;margin:0 auto 0 auto;text-align:left}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(2)>div:nth-child(2){display:table;border-top:1px solid #88A}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(2)>div:nth-child(2)>div{display:table-cell;vertical-align:middle}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(2)>div:nth-child(2)>div:first-child{text-align:center;padding:5px 0;width:40px}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(2)>div:nth-child(2)>div:nth-child(2){text-align:left;padding:5px;font-size:92%}.mw-parser-output .licenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(3){text-align:right}.mw-parser-output .licensetpl{display:none}.mw-parser-output .licenseContainer.wst-collapsible-box{clear:both;margin:0.25em 0 0.25em 0;font-size:95%;background-color:#f7f8ff;color:#202122;border:2px solid #88A;text-align:left;line-height:1.6}.mw-parser-output .wst-license-container-title{display:inline-block;padding:0.5em}.mw-parser-output .wst-license-container-content{background:transparent;color:inherit;margin:0;padding:3px;text-align:left}.mw-parser-output .licenseContainer.warningLicenseContainer>div:first-child{border-color:#b22222;background-color:#ffeeee;color:#202122}.mw-parser-output .licenseContainer.warningLicenseContainer>div:first-child>div:first-child>div:first-child>div:nth-child(2)>div:nth-child(2){border-color:#b22222;color:#202122}</style><div class=\"licenseContainer licenseBanner dynlayout-exempt\">\n",
            "<div><div><div><div>\n",
            "<p><span class=\"imageLeft\"><span class=\"mw-default-size\" typeof=\"mw:File\"><span><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/62/PD-icon.svg/48px-PD-icon.svg.png\" decoding=\"async\" width=\"48\" height=\"48\" class=\"mw-file-element\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/62/PD-icon.svg/72px-PD-icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/62/PD-icon.svg/96px-PD-icon.svg.png 2x\" data-file-width=\"196\" data-file-height=\"196\" /></span></span></span>\n",
            "</p>\n",
            "</div><div>\n",
            "<div>\n",
            "<p>This work is in the <b><a href=\"https://en.wikipedia.org/wiki/public_domain\" class=\"extiw\" title=\"w:public domain\">public domain</a></b> in the <b>United States</b> because it was published before January 1, 1929.\n",
            "</p>\n",
            "<hr />\n",
            "<p>The longest-living author of this work died in 1959, so this work is in the <b>public domain</b> in countries and areas where the copyright term is the author's <b>life plus 64 years or less</b>. This work may be in the <b>public domain</b> in countries and areas with longer native copyright terms that apply the <b><a href=\"https://en.wikipedia.org/wiki/Rule_of_the_shorter_term\" class=\"extiw\" title=\"w:Rule of the shorter term\">rule of the shorter term</a></b> to <i>foreign works</i>.\n",
            "</p>\n",
            "</div>\n",
            "</div><div>\n",
            "<p><span class=\"imageRight\"><span class=\"mw-default-size\" typeof=\"mw:File\"><span><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Flag_of_the_United_States.svg/92px-Flag_of_the_United_States.svg.png\" decoding=\"async\" width=\"92\" height=\"48\" class=\"mw-file-element\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Flag_of_the_United_States.svg/137px-Flag_of_the_United_States.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Flag_of_the_United_States.svg/183px-Flag_of_the_United_States.svg.png 2x\" data-file-width=\"1235\" data-file-height=\"650\" /></span></span></span>\n",
            "</p>\n",
            "</div></div></div></div>\n",
            "<div class=\"licensetpl\">\n",
            "<p><span class=\"licensetpl_short\">Public domain</span><span class=\"licensetpl_long\">Public domain</span><span class=\"licensetpl_link_req\">false</span><span class=\"licensetpl_attr_req\">false</span>\n",
            "</p>\n",
            "</div></div>\n",
            "<!-- \n",
            "NewPP limit report\n",
            "Parsed by mw‐api‐int.codfw.canary‐68d56cddbd‐89h97\n",
            "Cached time: 20241130221239\n",
            "Cache expiry: 2592000\n",
            "Reduced expiry: false\n",
            "Complications: [vary‐page‐id]\n",
            "CPU time usage: 0.181 seconds\n",
            "Real time usage: 0.284 seconds\n",
            "Preprocessor visited node count: 758/1000000\n",
            "Post‐expand include size: 27716/2097152 bytes\n",
            "Template argument size: 3476/2097152 bytes\n",
            "Highest expansion depth: 9/100\n",
            "Expensive parser function count: 2/500\n",
            "Unstrip recursion depth: 1/20\n",
            "Unstrip post‐expand size: 24337/5000000 bytes\n",
            "Lua time usage: 0.082/10.000 seconds\n",
            "Lua memory usage: 1474754/52428800 bytes\n",
            "Number of Wikibase entities loaded: 0/400\n",
            "-->\n",
            "<!--\n",
            "Transclusion expansion time report (%,ms,calls,template)\n",
            "100.00%  267.335      1 -total\n",
            " 30.44%   81.369      1 Template:Header\n",
            " 17.89%   47.822      1 Template:PD/US\n",
            " 14.74%   39.395      1 Page:Sax_Rohmer_-_Fire_Tongue.djvu/17\n",
            "  7.08%   18.933      1 Template:C\n",
            "  6.68%   17.845      1 Template:Di\n",
            "  4.03%   10.772      1 Page:Sax_Rohmer_-_Fire_Tongue.djvu/19\n",
            "  2.82%    7.551      2 Template:Wikt\n",
            "  2.71%    7.242      3 Template:Optional_style\n",
            "  2.69%    7.203     12 MediaWiki:Proofreadpage_pagenum_template\n",
            "-->\n",
            "\n",
            "<!-- Saved in parser cache with key enwikisource:pcache:idhash:2118663-0!canonical and timestamp 20241130221239 and revision id 10804536. Rendering was triggered because: api-parse\n",
            " -->\n",
            "</div><!--esi <esi:include src=\"/esitest-fa8a495983347898/content\" /> --><noscript><img src=\"https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?type=1x1&amp;useformat=desktop\" alt=\"\" width=\"1\" height=\"1\" style=\"border: none; position: absolute;\"></noscript>\n",
            "<div class=\"printfooter\" data-nosnippet=\"\">Retrieved from \"<a dir=\"ltr\" href=\"https://en.wikisource.org/w/index.php?title=Fire-Tongue/Chapter_1&amp;oldid=10804536\">https://en.wikisource.org/w/index.php?title=Fire-Tongue/Chapter_1&amp;oldid=10804536</a>\"</div></div>\n",
            "\t\t<div id=\"catlinks\" class=\"catlinks\" data-mw=\"interface\"><div id=\"mw-normal-catlinks\" class=\"mw-normal-catlinks\"><a href=\"/wiki/Special:Categories\" title=\"Special:Categories\">Category</a>: <ul><li><a href=\"/wiki/Category:PD-old-60-US\" title=\"Category:PD-old-60-US\">PD-old-60-US</a></li></ul></div><div id=\"mw-hidden-catlinks\" class=\"mw-hidden-catlinks mw-hidden-cats-hidden\">Hidden category: <ul><li><a href=\"/wiki/Category:Subpages\" title=\"Category:Subpages\">Subpages</a></li></ul></div></div>\n",
            "\t</div>\n",
            "</div>\n",
            "\n",
            "<div id=\"mw-navigation\">\n",
            "\t<h2>Navigation menu</h2>\n",
            "\t<div id=\"mw-head\">\n",
            "\t\t\n",
            "<nav id=\"p-personal\" class=\"mw-portlet mw-portlet-personal vector-user-menu-legacy vector-menu\" aria-labelledby=\"p-personal-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-personal-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t<li id=\"pt-anonuserpage\" class=\"mw-list-item\"><span title=\"The user page for the IP address you are editing as\">Not logged in</span></li><li id=\"pt-anontalk\" class=\"mw-list-item\"><a href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\" accesskey=\"n\"><span>Talk</span></a></li><li id=\"pt-anoncontribs\" class=\"mw-list-item\"><a href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\" accesskey=\"y\"><span>Contributions</span></a></li><li id=\"pt-createaccount\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Fire-Tongue%2FChapter+1\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\"><span>Create account</span></a></li><li id=\"pt-login\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Fire-Tongue%2FChapter+1\" title=\"You are encouraged to log in; however, it is not mandatory [o]\" accesskey=\"o\"><span>Log in</span></a></li>\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "\t\t<div id=\"left-navigation\">\n",
            "\t\t\t\n",
            "<nav id=\"p-namespaces\" class=\"mw-portlet mw-portlet-namespaces vector-menu-tabs vector-menu-tabs-legacy vector-menu\" aria-labelledby=\"p-namespaces-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-namespaces-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t<li id=\"ca-nstab-main\" class=\"selected mw-list-item\"><a href=\"/wiki/Fire-Tongue/Chapter_1\" title=\"View the content page [c]\" accesskey=\"c\"><span>Page</span></a></li><li id=\"ca-proofread-source\" class=\"mw-list-item\"><a title=\"Scanned edition used to establish this text\" href=\"/wiki/Index:Sax_Rohmer_-_Fire_Tongue.djvu\"><span>Source</span></a></li><li id=\"ca-talk\" class=\"new mw-list-item\"><a href=\"/w/index.php?title=Talk:Fire-Tongue/Chapter_1&amp;action=edit&amp;redlink=1\" rel=\"discussion\" class=\"new\" title=\"Discussion about the content page (page does not exist) [t]\" accesskey=\"t\"><span>Discussion</span></a></li>\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "\t\t\t\n",
            "<nav id=\"p-variants\" class=\"mw-portlet mw-portlet-variants emptyPortlet vector-menu-dropdown vector-menu\" aria-labelledby=\"p-variants-label\"  >\n",
            "\t<input type=\"checkbox\"\n",
            "\t\tid=\"p-variants-checkbox\"\n",
            "\t\trole=\"button\"\n",
            "\t\taria-haspopup=\"true\"\n",
            "\t\tdata-event-name=\"ui.dropdown-p-variants\"\n",
            "\t\tclass=\"vector-menu-checkbox\"\n",
            "\t\taria-labelledby=\"p-variants-label\"\n",
            "\t>\n",
            "\t<label\n",
            "\t\tid=\"p-variants-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">English</span>\n",
            "\t</label>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "\t\t</div>\n",
            "\t\t<div id=\"right-navigation\">\n",
            "\t\t\t\n",
            "<nav id=\"p-views\" class=\"mw-portlet mw-portlet-views vector-menu-tabs vector-menu-tabs-legacy vector-menu\" aria-labelledby=\"p-views-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-views-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">Views</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t<li id=\"ca-view\" class=\"selected mw-list-item\"><a href=\"/wiki/Fire-Tongue/Chapter_1\"><span>Read</span></a></li><li id=\"ca-edit\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Fire-Tongue/Chapter_1&amp;action=edit\" title=\"Edit this page [e]\" accesskey=\"e\"><span>Edit</span></a></li><li id=\"ca-history\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Fire-Tongue/Chapter_1&amp;action=history\" title=\"Past revisions of this page [h]\" accesskey=\"h\"><span>View history</span></a></li>\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "\t\t\t\n",
            "<nav id=\"p-cactions\" class=\"mw-portlet mw-portlet-cactions emptyPortlet vector-menu-dropdown vector-menu\" aria-labelledby=\"p-cactions-label\"  title=\"More options\" >\n",
            "\t<input type=\"checkbox\"\n",
            "\t\tid=\"p-cactions-checkbox\"\n",
            "\t\trole=\"button\"\n",
            "\t\taria-haspopup=\"true\"\n",
            "\t\tdata-event-name=\"ui.dropdown-p-cactions\"\n",
            "\t\tclass=\"vector-menu-checkbox\"\n",
            "\t\taria-labelledby=\"p-cactions-label\"\n",
            "\t>\n",
            "\t<label\n",
            "\t\tid=\"p-cactions-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">More</span>\n",
            "\t</label>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "\t\t\t\n",
            "<div id=\"p-search\" role=\"search\" class=\"vector-search-box-vue  vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box\">\n",
            "\t<h3 >Search</h3>\n",
            "\t<form action=\"/w/index.php\" id=\"searchform\" class=\"vector-search-box-form\">\n",
            "\t\t<div id=\"simpleSearch\"\n",
            "\t\t\tclass=\"vector-search-box-inner\"\n",
            "\t\t\t data-search-loc=\"header-navigation\">\n",
            "\t\t\t<input class=\"vector-search-box-input\"\n",
            "\t\t\t\t type=\"search\" name=\"search\" placeholder=\"Search Wikisource\" aria-label=\"Search Wikisource\" autocapitalize=\"sentences\" title=\"Search Wikisource [f]\" accesskey=\"f\" id=\"searchInput\"\n",
            "\t\t\t>\n",
            "\t\t\t<input type=\"hidden\" name=\"title\" value=\"Special:Search\">\n",
            "\t\t\t<input id=\"mw-searchButton\"\n",
            "\t\t\t\t class=\"searchButton mw-fallbackSearchButton\" type=\"submit\" name=\"fulltext\" title=\"Search the pages for this text\" value=\"Search\">\n",
            "\t\t\t<input id=\"searchButton\"\n",
            "\t\t\t\t class=\"searchButton\" type=\"submit\" name=\"go\" title=\"Go to a page with this exact name if it exists\" value=\"Go\">\n",
            "\t\t</div>\n",
            "\t</form>\n",
            "</div>\n",
            "\n",
            "\t\t</div>\n",
            "\t</div>\n",
            "\t\n",
            "<div id=\"mw-panel\" class=\"vector-legacy-sidebar\">\n",
            "\t<div id=\"p-logo\" role=\"banner\">\n",
            "\t\t<a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\"\n",
            "\t\t\ttitle=\"Visit the main page\"></a>\n",
            "\t</div>\n",
            "\t\n",
            "<nav id=\"p-navigation\" class=\"mw-portlet mw-portlet-navigation vector-menu-portal portal vector-menu\" aria-labelledby=\"p-navigation-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-navigation-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">Navigation</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t<li id=\"n-mainpage\" class=\"mw-list-item\"><a href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\" accesskey=\"z\"><span>Main Page</span></a></li><li id=\"n-portal\" class=\"mw-list-item\"><a href=\"/wiki/Wikisource:Community_portal\" title=\"About the project, what you can do, where to find things\"><span>Community portal</span></a></li><li id=\"n-scriptorium\" class=\"mw-list-item\"><a href=\"/wiki/Wikisource:Scriptorium\"><span>Central discussion</span></a></li><li id=\"n-recentchanges\" class=\"mw-list-item\"><a href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes in the wiki [r]\" accesskey=\"r\"><span>Recent changes</span></a></li><li id=\"n-subjectindex\" class=\"mw-list-item\"><a href=\"/wiki/Portal:Portals\"><span>Subject index</span></a></li><li id=\"n-categoryauthors\" class=\"mw-list-item\"><a href=\"/wiki/Category:Authors_by_alphabetical_order\"><span>Authors</span></a></li><li id=\"n-randomwork\" class=\"mw-list-item\"><a href=\"/wiki/Special:RandomRootpage/Main\"><span>Random work</span></a></li><li id=\"n-randomauthor\" class=\"mw-list-item\"><a href=\"/wiki/Special:RandomRootpage/Author\"><span>Random author</span></a></li><li id=\"n-randomindex\" class=\"mw-list-item\"><a href=\"/wiki/Special:RandomRootpage/Index\"><span>Random transcription</span></a></li><li id=\"n-help\" class=\"mw-list-item\"><a href=\"/wiki/Help:Contents\" title=\"The place to find out\"><span>Help</span></a></li><li id=\"n-sitesupport\" class=\"mw-list-item\"><a href=\"//donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikisource.org&amp;uselang=en\" title=\"Support us\"><span>Donate</span></a></li>\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "\t\n",
            "<nav id=\"p-do\" class=\"mw-portlet mw-portlet-do emptyPortlet vector-menu-portal portal vector-menu\" aria-labelledby=\"p-do-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-do-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">Display Options</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "<nav id=\"p-tb\" class=\"mw-portlet mw-portlet-tb vector-menu-portal portal vector-menu\" aria-labelledby=\"p-tb-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-tb-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">Tools</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t<li id=\"t-whatlinkshere\" class=\"mw-list-item\"><a href=\"/wiki/Special:WhatLinksHere/Fire-Tongue/Chapter_1\" title=\"A list of all wiki pages that link here [j]\" accesskey=\"j\"><span>What links here</span></a></li><li id=\"t-recentchangeslinked\" class=\"mw-list-item\"><a href=\"/wiki/Special:RecentChangesLinked/Fire-Tongue/Chapter_1\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\" accesskey=\"k\"><span>Related changes</span></a></li><li id=\"t-specialpages\" class=\"mw-list-item\"><a href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\" accesskey=\"q\"><span>Special pages</span></a></li><li id=\"t-permalink\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Fire-Tongue/Chapter_1&amp;oldid=10804536\" title=\"Permanent link to this revision of this page\"><span>Permanent link</span></a></li><li id=\"t-info\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Fire-Tongue/Chapter_1&amp;action=info\" title=\"More information about this page\"><span>Page information</span></a></li><li id=\"t-cite\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Fire-Tongue%2FChapter_1&amp;id=10804536&amp;wpFormIdentifier=titleform\" title=\"Information on how to cite this page\"><span>Cite this page</span></a></li><li id=\"t-urlshortener\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:UrlShortener&amp;url=https%3A%2F%2Fen.wikisource.org%2Fwiki%2FFire-Tongue%2FChapter_1\"><span>Get shortened URL</span></a></li><li id=\"t-urlshortener-qrcode\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:QrCode&amp;url=https%3A%2F%2Fen.wikisource.org%2Fwiki%2FFire-Tongue%2FChapter_1\"><span>Download QR code</span></a></li>\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "<nav id=\"p-electronpdfservice-sidebar-portlet-heading\" class=\"mw-portlet mw-portlet-electronpdfservice-sidebar-portlet-heading vector-menu-portal portal vector-menu\" aria-labelledby=\"p-electronpdfservice-sidebar-portlet-heading-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-electronpdfservice-sidebar-portlet-heading-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">Print/export</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t<li id=\"t-print\" class=\"mw-list-item\"><a href=\"javascript:print();\" rel=\"alternate\" title=\"Printable version of this page [p]\" accesskey=\"p\"><span>Printable version</span></a></li><li id=\"wikisource-download-epub\" class=\"mw-list-item\"><a title=\"Download an EPUB version of this work\" href=\"https://ws-export.wmcloud.org/?format=epub&amp;lang=en&amp;page=Fire-Tongue%2FChapter_1\"><span>Download EPUB</span></a></li><li id=\"wikisource-download-mobi\" class=\"mw-list-item\"><a title=\"Download a MOBI version of this work\" href=\"https://ws-export.wmcloud.org/?format=mobi&amp;lang=en&amp;page=Fire-Tongue%2FChapter_1\"><span>Download MOBI</span></a></li><li id=\"wikisource-download-pdf\" class=\"mw-list-item\"><a title=\"Download a PDF version of this work\" href=\"https://ws-export.wmcloud.org/?format=pdf&amp;lang=en&amp;page=Fire-Tongue%2FChapter_1\"><span>Download PDF</span></a></li><li id=\"wikisource-download-choose\" class=\"mw-list-item\"><a title=\"Open a form to choose other formats and fonts etc.\" href=\"https://ws-export.wmcloud.org/?lang=en&amp;title=Fire-Tongue%2FChapter_1\"><span>Other formats</span></a></li>\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "<nav id=\"p-wikibase-otherprojects\" class=\"mw-portlet mw-portlet-wikibase-otherprojects emptyPortlet vector-menu-portal portal vector-menu\" aria-labelledby=\"p-wikibase-otherprojects-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-wikibase-otherprojects-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">In other projects</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t</ul>\n",
            "\t\t\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "\t\n",
            "<nav id=\"p-lang\" class=\"mw-portlet mw-portlet-lang vector-menu-portal portal vector-menu\" aria-labelledby=\"p-lang-label\"  >\n",
            "\t<h3\n",
            "\t\tid=\"p-lang-label\"\n",
            "\t\t\n",
            "\t\tclass=\"vector-menu-heading \"\n",
            "\t>\n",
            "\t\t<span class=\"vector-menu-heading-label\">In other languages</span>\n",
            "\t</h3>\n",
            "\t<div class=\"vector-menu-content\">\n",
            "\t\t\n",
            "\t\t<ul class=\"vector-menu-content-list\">\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t</ul>\n",
            "\t\t<div class=\"after-portlet after-portlet-lang\"><span class=\"uls-after-portlet-link\"></span><span class=\"wb-langlinks-add wb-langlinks-link\"><a href=\"https://www.wikidata.org/wiki/Special:NewItem?site=enwikisource&amp;page=Fire-Tongue%2FChapter+1\" title=\"Add interlanguage links\" class=\"wbc-editpage\">Add links</a></span></div>\n",
            "\t</div>\n",
            "</nav>\n",
            "\n",
            "</div>\n",
            "\n",
            "</div>\n",
            "\n",
            "<footer id=\"footer\" class=\"mw-footer\" >\n",
            "\t<ul id=\"footer-info\">\n",
            "\t<li id=\"footer-info-lastmod\"> This page was last edited on 3 January 2021, at 04:38.</li>\n",
            "\t<li id=\"footer-info-copyright\">Text is available under the <a rel=\"nofollow\" class=\"external text\" href=\"//creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike License</a>; additional terms may apply.  By using this site, you agree to the <a class=\"external text\" href=\"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use\">Terms of Use</a> and <a class=\"external text\" href=\"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\">Privacy Policy.</a></li>\n",
            "</ul>\n",
            "\n",
            "\t<ul id=\"footer-places\">\n",
            "\t<li id=\"footer-places-privacy\"><a href=\"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\">Privacy policy</a></li>\n",
            "\t<li id=\"footer-places-about\"><a href=\"/wiki/Wikisource:About\">About Wikisource</a></li>\n",
            "\t<li id=\"footer-places-disclaimers\"><a href=\"/wiki/Wikisource:General_disclaimer\">Disclaimers</a></li>\n",
            "\t<li id=\"footer-places-wm-codeofconduct\"><a href=\"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct\">Code of Conduct</a></li>\n",
            "\t<li id=\"footer-places-developers\"><a href=\"https://developer.wikimedia.org\">Developers</a></li>\n",
            "\t<li id=\"footer-places-statslink\"><a href=\"https://stats.wikimedia.org/#/en.wikisource.org\">Statistics</a></li>\n",
            "\t<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement\">Cookie statement</a></li>\n",
            "\t<li id=\"footer-places-mobileview\"><a href=\"//en.m.wikisource.org/w/index.php?title=Fire-Tongue/Chapter_1&amp;mobileaction=toggle_view_mobile\" class=\"noprint stopMobileRedirectToggle\">Mobile view</a></li>\n",
            "</ul>\n",
            "\n",
            "\t<ul id=\"footer-icons\" class=\"noprint\">\n",
            "\t<li id=\"footer-copyrightico\"><a href=\"https://wikimediafoundation.org/\" class=\"cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled\"><img src=\"/static/images/footer/wikimedia-button.svg\" width=\"84\" height=\"29\" alt=\"Wikimedia Foundation\" loading=\"lazy\"></a></li>\n",
            "\t<li id=\"footer-poweredbyico\"><a href=\"https://www.mediawiki.org/\" class=\"cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled\"><img src=\"/w/resources/assets/poweredby_mediawiki.svg\" alt=\"Powered by MediaWiki\" width=\"88\" height=\"31\" loading=\"lazy\"></a></li>\n",
            "</ul>\n",
            "\n",
            "</footer>\n",
            "\n",
            "<script>(RLQ=window.RLQ||[]).push(function(){mw.log.warn(\"This page is using the deprecated ResourceLoader module \\\"codex-search-styles\\\".\\n[1.43] Use a CodexModule with codexComponents to set your specific components used: https://www.mediawiki.org/wiki/Codex#Using_a_limited_subset_of_components\");mw.config.set({\"wgHostname\":\"mw-web.codfw.main-5c59558b9d-7w877\",\"wgBackendResponseTime\":90,\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"0.181\",\"walltime\":\"0.284\",\"ppvisitednodes\":{\"value\":758,\"limit\":1000000},\"postexpandincludesize\":{\"value\":27716,\"limit\":2097152},\"templateargumentsize\":{\"value\":3476,\"limit\":2097152},\"expansiondepth\":{\"value\":9,\"limit\":100},\"expensivefunctioncount\":{\"value\":2,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":24337,\"limit\":5000000},\"entityaccesscount\":{\"value\":0,\"limit\":400},\"timingprofile\":[\"100.00%  267.335      1 -total\",\" 30.44%   81.369      1 Template:Header\",\" 17.89%   47.822      1 Template:PD/US\",\" 14.74%   39.395      1 Page:Sax_Rohmer_-_Fire_Tongue.djvu/17\",\"  7.08%   18.933      1 Template:C\",\"  6.68%   17.845      1 Template:Di\",\"  4.03%   10.772      1 Page:Sax_Rohmer_-_Fire_Tongue.djvu/19\",\"  2.82%    7.551      2 Template:Wikt\",\"  2.71%    7.242      3 Template:Optional_style\",\"  2.69%    7.203     12 MediaWiki:Proofreadpage_pagenum_template\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.082\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":1474754,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw-api-int.codfw.canary-68d56cddbd-89h97\",\"timestamp\":\"20241130221239\",\"ttl\":2592000,\"transientcontent\":false}}});});</script>\n",
            "</body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split text according to given chars\n",
        "import re\n",
        "preprocessed = re.split(r'([,.:;?_!=\\-\\\"<>#\\{\\}\\'$\\&/()\\[\\]+]|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rc7zlTUVNk7",
        "outputId": "10cdf173-3078-4058-9cb0-977afcb21255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVCEUmVbWL-f",
        "outputId": "3b5890ab-4748-4a96-dbe6-807b25e956f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<', '!', 'DOCTYPE', 'html', '>', '<', 'html', 'class', '=', '\"', 'client', '-', 'nojs', '\"', 'lang', '=', '\"', 'en', '\"', 'dir', '=', '\"', 'ltr', '\"', '>', '<', 'head', '>', '<', 'meta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assign number to each token and sort them alphabetically\n",
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "#total unique characters\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuF3dk3oba8w",
        "outputId": "d5fa2d5f-f48b-4232-bea4-840d564d959b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token: integer for integer, token in enumerate(all_words)}\n",
        "#print the first 50 tokens\n",
        "for i, item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i >= 50:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPuzB8oTcg2P",
        "outputId": "147c25b3-e6e7-4645-cafe-6449dc8087d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "('#', 2)\n",
            "('$', 3)\n",
            "('%', 4)\n",
            "('%2C', 5)\n",
            "('&', 6)\n",
            "(\"'\", 7)\n",
            "('(', 8)\n",
            "(')', 9)\n",
            "('*', 10)\n",
            "('+', 11)\n",
            "(',', 12)\n",
            "('-', 13)\n",
            "('.', 14)\n",
            "('/', 15)\n",
            "('0', 16)\n",
            "('0%', 17)\n",
            "('00%', 18)\n",
            "('000', 19)\n",
            "('003', 20)\n",
            "('035', 21)\n",
            "('03fa0f089ae5', 22)\n",
            "('04', 23)\n",
            "('074', 24)\n",
            "('1', 25)\n",
            "('10', 26)\n",
            "('100', 27)\n",
            "('100%', 28)\n",
            "('1000000', 29)\n",
            "('10804536', 30)\n",
            "('11', 31)\n",
            "('1120', 32)\n",
            "('113', 33)\n",
            "('114', 34)\n",
            "('12', 35)\n",
            "('12%', 36)\n",
            "('120%', 37)\n",
            "('1235', 38)\n",
            "('13', 39)\n",
            "('137px', 40)\n",
            "('14', 41)\n",
            "('147', 42)\n",
            "('1474754', 43)\n",
            "('15%', 44)\n",
            "('160', 45)\n",
            "('167', 46)\n",
            "('17', 47)\n",
            "('18', 48)\n",
            "('182%', 49)\n",
            "('183px', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert token to id, convert id to token\n",
        "class SimpleTokenizerV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i : s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    #convert sentence into list of ids\n",
        "    preprocessed = re.split(r'([,.:;?_!=\\-\\\"<>#\\{\\}\\'$\\&/()\\[\\]+]|--|\\s)', text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "    #map token to id\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    #convert id list to words\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    #remove space before given symbols\n",
        "    text = re.sub(r'\\s+([,.?\"()\\'])', r'\\1', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "0x7JWOi1eN-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "text = \"\"\"\n",
        "One summer's evening when the little clock upon his table was rapidly approaching the much-desired hour,\n",
        "\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)\n",
        "print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqpWwcBtgAA0",
        "outputId": "07992e6e-897b-49d1-f0d0-5960c08a756b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[332, 1706, 7, 1567, 870, 1934, 1743, 1179, 687, 1825, 1030, 1722, 1869, 1503, 531, 1743, 1262, 13, 776, 1036, 12]\n",
            "One summer' s evening when the little clock upon his table was rapidly approaching the much - desired hour,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the problem is, tokenizer can't handle word not in the text\n",
        "text = \"Hello, do you like tea?\"\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "N66HKhZEiIqG",
        "outputId": "c494a37f-cb4a-4ea7-97fd-2dc91ead741a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Hello'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-04179c608e32>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#the problem is, tokenizer can't handle word not in the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hello, do you like tea?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-348906ba76b4>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#map token to id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-348906ba76b4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#map token to id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Hello'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#handle unseen words\n",
        "#add to special tokens, *|unk|* and *|endoftext|*, every unseen word map to token |unk|\n",
        "#|endoftext| as symbol to seperate different text source\n",
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"*|endoftext|*\", \"*|unk|*\"])\n",
        "vocab = {token : integer for integer, token in enumerate(all_tokens)}\n",
        "print(len(vocab.items()))\n",
        "\n",
        "for i, item in enumerate(list(vocab.items())[-10:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Nspvr0inu1",
        "outputId": "450698e8-e709-4c75-a4e6-dd366f557d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2001\n",
            "('z', 1991)\n",
            "('{', 1992)\n",
            "('|', 1993)\n",
            "('}', 1994)\n",
            "('~ext', 1995)\n",
            "('—', 1996)\n",
            "('←', 1997)\n",
            "('→', 1998)\n",
            "('*|endoftext|*', 1999)\n",
            "('*|unk|*', 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert token to id, convert id to token\n",
        "class SimpleTokenizerV2:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i : s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    #convert sentence into list of ids\n",
        "    preprocessed = re.split(r'([,.:;?_!=\\-\\\"<>#\\{\\}\\'$\\&/()\\[\\]+]|--|\\s)', text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "    print(f\"encode preprocessed: {preprocessed}\")\n",
        "    #add unk token for unseen word\n",
        "    preprocessed = [item if item in self.str_to_int else \"*|unk|*\" for item in preprocessed]\n",
        "    #map token to id\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    #convert id list to words\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    #remove space before given symbols\n",
        "    text = re.sub(r'\\s+([,.?\"()\\'])', r'\\1', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "WalXjd8bkW1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit rerraces of palace.\"\n",
        "#notice space in the front and end\n",
        "text  = \" *|endoftext|* \".join((text1,text2))\n",
        "\n",
        "print(text)\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)\n",
        "print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUlHufTFkvOd",
        "outputId": "4e74f425-76c1-48a6-e9b4-24cdf0b9e865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? *|endoftext|* In the sunlit rerraces of palace.\n",
            "encode preprocessed: ['Hello', ',', 'do', 'you', 'like', 'tea', '?', '*|endoftext|*', 'In', 'the', 'sunlit', 'rerraces', 'of', 'palace', '.']\n",
            "[2000, 12, 805, 1988, 1169, 2000, 159, 1999, 276, 1743, 2000, 2000, 1325, 2000, 14]\n",
            "*|unk|*, do you like *|unk|*? *|endoftext|* In the *|unk|* *|unk|* of *|unk|*.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "#count word frequency and split word as char collection\n",
        "def get_vocab(data):\n",
        "  vocab = defaultdict(int)\n",
        "  for word in data.split():\n",
        "          vocab[' '.join(list(word))] += 1\n",
        "  return vocab\n",
        "\n",
        "vocab = get_vocab(\"low low low low low lower lower newest newest newest newest newest newest widest widest widest\")\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-KM6-0a7rby",
        "outputId": "d22a0d32-b840-4341-a67e-b1d66b432673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {'l o w': 5, 'l o w e r': 2, 'n e w e s t': 6, 'w i d e s t': 3})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count the freqency of neighboring char pair\n",
        "from collections import Counter\n",
        "def get_stats(vocab):\n",
        "  pairs = Counter()\n",
        "  for word, freq in vocab.items():\n",
        "    symbols = word.split()\n",
        "    #check neighboring char pair\n",
        "    for i in range(len(symbols) - 1):\n",
        "      pairs[symbols[i], symbols[i+1]] += freq\n",
        "\n",
        "  return pairs\n",
        "\n",
        "pairs = get_stats(vocab)\n",
        "print(pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZjP46bbAoZy",
        "outputId": "1b6d2c1b-be2f-40cb-845c-0116e2a324e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({('e', 's'): 9, ('s', 't'): 9, ('w', 'e'): 8, ('l', 'o'): 7, ('o', 'w'): 7, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3, ('e', 'r'): 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge most frequent pair as one\n",
        "def merge_vocab(pair, vocab):\n",
        "  new_vocab = {}\n",
        "  neighboring_chars = ' '.join(pair)\n",
        "  #combine two char as one\n",
        "  replacement = ''.join(pair)\n",
        "  for word in vocab:\n",
        "    new_word = word.replace(neighboring_chars, replacement)\n",
        "    new_vocab[new_word] = vocab[word]\n",
        "\n",
        "  return new_vocab\n",
        "\n",
        "most_frequent = max(pairs, key=pairs.get)\n",
        "new_vocab = merge_vocab(most_frequent, vocab)\n",
        "print(new_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NelNTW_GBvZV",
        "outputId": "1b382e96-81f7-40d4-8214-c35d6be7207b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'l o w': 5, 'l o w e r': 2, 'n e w es t': 6, 'w i d es t': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#let's combine all steps and iterate for given times\n",
        "def byte_pair_encoding(vocab, num_merges):\n",
        "  for i in range(num_merges):\n",
        "    pairs = get_stats(vocab)\n",
        "    if not pairs:\n",
        "      break\n",
        "    most_frequent = max(pairs, key=pairs.get)\n",
        "    vocab = merge_vocab(most_frequent, vocab)\n",
        "    print(f\"merget: {i+1}, most frequent: {most_frequent}\")\n",
        "  return vocab\n",
        "\n",
        "result_vocab = byte_pair_encoding(vocab, 20)\n",
        "print(\"final vocab\")\n",
        "for word in result_vocab:\n",
        "  print(f\"{word}: {result_vocab[word]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmTwS1etcndx",
        "outputId": "e2a58869-f7b4-4bc0-d222-e1eb2f07d1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merget: 1, most frequent: ('e', 's')\n",
            "merget: 2, most frequent: ('es', 't')\n",
            "merget: 3, most frequent: ('l', 'o')\n",
            "merget: 4, most frequent: ('lo', 'w')\n",
            "merget: 5, most frequent: ('n', 'e')\n",
            "merget: 6, most frequent: ('ne', 'w')\n",
            "merget: 7, most frequent: ('new', 'est')\n",
            "merget: 8, most frequent: ('w', 'i')\n",
            "merget: 9, most frequent: ('wi', 'd')\n",
            "merget: 10, most frequent: ('wid', 'est')\n",
            "merget: 11, most frequent: ('low', 'e')\n",
            "merget: 12, most frequent: ('lowe', 'r')\n",
            "final vocab\n",
            "low: 5\n",
            "lower: 2\n",
            "newest: 6\n",
            "widest: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QqId9JAdavv",
        "outputId": "3d2911a9-7e46-49f1-93de-10414bea5130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('gpt2')\n"
      ],
      "metadata": {
        "id": "wj8RQcpthTK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\"Hello, do you like a cup of chinese tea? *|endoftext|* In the sunlit terraces\"\n",
        "       \"of someunknowPlace.\")\n",
        "integers = tokenizer.encode(text, allowed_special={\"*|endoftext|*\"})\n",
        "print(integers)\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzTjbTPnhnsC",
        "outputId": "ce7df52e-b814-4601-b03c-00d20bdb10d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 257, 6508, 286, 442, 3762, 8887, 30, 1635, 91, 437, 1659, 5239, 91, 9, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 2954, 2197, 27271, 13]\n",
            "Hello, do you like a cup of chinese tea? *|endoftext|* In the sunlit terracesof someunknowPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding('gpt2')\n",
        "\n",
        "integers = tokenizer.encode(\"Akwirw ier\")\n",
        "print(integers)\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJbW6PVCkP5H",
        "outputId": "e4247708-0b3a-4165-b596-9afa44f9a442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33901, 86, 343, 86, 220, 959]\n",
            "Akwirw ier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ],
      "metadata": {
        "id": "Gk4-lpInfStH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"fire-tongue.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "pos = raw_text.index(\"His investigation of the case of the man\")\n",
        "training_text = raw_text[pos:]\n",
        "encoded_text = tokenizer.encode(training_text)\n",
        "print(len(encoded_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWsuFBiVfJVh",
        "outputId": "c486cd02-6840-4cd8-826e-6f1eb10345b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 4\n",
        "#window size dertermines how many tokens as input\n",
        "x = encoded_text[:window_size]\n",
        "#right shift by one place to get the predict word\n",
        "y = encoded_text[1 : window_size+1]\n",
        "print(f\"x:  {x}\")\n",
        "print(f\"y:       {y}\")\n",
        "\n",
        "for i in range(1, window_size + 1):\n",
        "  input = encoded_text[:i]\n",
        "  expect = encoded_text[i]\n",
        "  print(input, \"----->\", expect)\n",
        "\n",
        "for i in range(1, window_size + 1):\n",
        "  input = encoded_text[:i]\n",
        "  expect = encoded_text[i]\n",
        "  print(tokenizer.decode(input), \"----->\" ,tokenizer.decode([expect]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfIDZPcffQXs",
        "outputId": "58d4ee3c-0a14-4fe0-e165-ea68eea8008b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:  [6653, 3645, 286, 262]\n",
            "y:       [3645, 286, 262, 1339]\n",
            "[6653] -----> 3645\n",
            "[6653, 3645] -----> 286\n",
            "[6653, 3645, 286] -----> 262\n",
            "[6653, 3645, 286, 262] -----> 1339\n",
            "His ----->  investigation\n",
            "His investigation ----->  of\n",
            "His investigation of ----->  the\n",
            "His investigation of the ----->  case\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, input_text, tokenizer, window_size, shift):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "    token_ids = tokenizer.encode(input_text)\n",
        "    for i in range(0, len(token_ids) - window_size, shift):\n",
        "      #move the window to the right by steps given by shift\n",
        "      input_chunk = token_ids[i : i + window_size]\n",
        "      target_chunk = token_ids[i+1 : i + window_size + 1]\n",
        "      #tensor basically the same as a vector\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    #enable to use len() to get length\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    #enable to use [] to get item just like array\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n"
      ],
      "metadata": {
        "id": "sJw46pXmpohK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(text, batch_size = 4, window_size = 256, shift = 128, shuffle = True, drop_last = True, num_workers = 0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(text, tokenizer, window_size, shift)\n",
        "  \"\"\"\n",
        "  drap_last: whether to drop the last batch if items in the batch is\n",
        "  not enough specified by batch_size\n",
        "\n",
        "  num_workers: how many threads used to run the dataloader\n",
        "  \"\"\"\n",
        "  dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = shuffle,\n",
        "                          drop_last = drop_last, num_workers = num_workers)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "W7TlTf-luXVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"fire-tongue.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size = 1, window_size = 4,\n",
        "                                  shift = 1, shuffle = False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RazOZ4qvhlT",
        "outputId": "94cc4a65-bd44-414f-dca1-7c97e41681a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[   27,     0, 18227,  4177]]), tensor([[    0, 18227,  4177,    56]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shift set to 4 means given the input, the model should expect the following four words\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size = 16, window_size=4, shift=4, shuffle = False)\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(f\"inputs\\n: {inputs}\")\n",
        "print(f\"outputs:\\n: {targets}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki-xOW34yMo9",
        "outputId": "4be96298-fc9a-41cc-c914-824251d28f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            ": tensor([[   27,     0, 18227,  4177],\n",
            "        [   56, 11401, 27711,    29],\n",
            "        [  198,    27,  6494,  1398],\n",
            "        [ 2625, 16366,    12,  3919],\n",
            "        [ 8457,     1, 42392,  2625],\n",
            "        [  268,     1, 26672,  2625],\n",
            "        [   75,  2213,  5320,   198],\n",
            "        [   27,  2256,    29,   198],\n",
            "        [   27, 28961, 34534,   316],\n",
            "        [ 2625, 48504,    12,    23],\n",
            "        [ 5320,   198,    27,  7839],\n",
            "        [   29, 13543,    12,    51],\n",
            "        [  506,   518,    14, 14126],\n",
            "        [  352,   532, 11145,   271],\n",
            "        [ 1668,    11,   262,  1479],\n",
            "        [ 2691,  5888,  3556,  7839]])\n",
            "outputs:\n",
            ": tensor([[    0, 18227,  4177,    56],\n",
            "        [11401, 27711,    29,   198],\n",
            "        [   27,  6494,  1398,  2625],\n",
            "        [16366,    12,  3919,  8457],\n",
            "        [    1, 42392,  2625,   268],\n",
            "        [    1, 26672,  2625,    75],\n",
            "        [ 2213,  5320,   198,    27],\n",
            "        [ 2256,    29,   198,    27],\n",
            "        [28961, 34534,   316,  2625],\n",
            "        [48504,    12,    23,  5320],\n",
            "        [  198,    27,  7839,    29],\n",
            "        [13543,    12,    51,   506],\n",
            "        [  518,    14, 14126,   352],\n",
            "        [  532, 11145,   271,  1668],\n",
            "        [   11,   262,  1479,  2691],\n",
            "        [ 5888,  3556,  7839,    29]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLX1ZfqTc3Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#random seed to generate random values for vector\n",
        "torch.manual_seed(321)\n",
        "vocab_size = 6 #6 tokens\n",
        "output_dim = 3 #each token map to vector with length 3\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTCgkjK1Ujpb",
        "outputId": "40acaba3-0cad-43a4-8cc3-1ce8ba2edb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1302,  0.4343, -0.4491],\n",
            "        [-1.0824,  2.5830, -0.3784],\n",
            "        [-0.6681, -0.4460, -0.4942],\n",
            "        [-1.0153,  0.9791,  1.5577],\n",
            "        [-0.3924,  0.4283,  0.6376],\n",
            "        [-0.5494,  0.7509,  1.7671]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2, 3, 5, 1])\n",
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li_e2So1Vp3B",
        "outputId": "cbe4d109-a5ca-455b-bc06-1174cea8eea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6681, -0.4460, -0.4942],\n",
            "        [-1.0153,  0.9791,  1.5577],\n",
            "        [-0.5494,  0.7509,  1.7671],\n",
            "        [-1.0824,  2.5830, -0.3784]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size = 8, window_size = max_length, shift = max_length, shuffle = False)\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(f\"Token IDs: \\n\", inputs)\n",
        "print(\"\\nInputs shape: \\n\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_J-Wq65c4nu",
        "outputId": "890f4aa9-0540-4249-eb94-e92ec2a8653e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: \n",
            " tensor([[   27,     0, 18227,  4177],\n",
            "        [   56, 11401, 27711,    29],\n",
            "        [  198,    27,  6494,  1398],\n",
            "        [ 2625, 16366,    12,  3919],\n",
            "        [ 8457, 15879,    12, 30053],\n",
            "        [   12, 16129,    12,   259],\n",
            "        [   12, 25677,    12, 25616],\n",
            "        [15879,    12, 30053,    12]])\n",
            "\n",
            "Inputs shape: \n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding('gpt2')\n",
        "vocab_size = encoding.n_vocab\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEQnUWEhdRBX",
        "outputId": "9ba1fdec-94d5-4c0d-e10f-aac4e71d6c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim = 256\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "DTAJf_UBxwvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8za3vjtOyQEL",
        "outputId": "7be9d835-baee-412a-faab-a8cedc2f482f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "#torch.arange(context_length) generate [0, 1, 2, 3]\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2cA1I5FzAuN",
        "outputId": "a382f298-055e-4d7c-c31e-b68d9e5c01e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNG5tgrazzB2",
        "outputId": "903f02c3-df58-4e19-f96b-dfb591701f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.4707, -0.5548,  1.6110,  ...,  2.0232,  0.1589, -1.4503],\n",
            "         [ 2.7354,  0.7785,  0.2636,  ...,  0.6698, -4.6256,  0.2454],\n",
            "         [-2.9696,  1.4847,  0.8292,  ...,  1.4316,  0.0567, -0.5988],\n",
            "         [ 0.3262,  0.9588,  0.6520,  ..., -0.2436,  2.6629, -0.4146]],\n",
            "\n",
            "        [[-0.2752, -2.3073, -0.1332,  ...,  0.9190, -2.2662,  1.1484],\n",
            "         [ 1.8600,  0.3578,  1.3777,  ...,  2.2377, -4.1326,  2.8430],\n",
            "         [-2.9329, -0.1163,  0.0754,  ...,  2.0116, -3.3202, -0.0452],\n",
            "         [ 0.0766,  0.1125,  1.7159,  ...,  1.9491, -0.2940, -1.6671]],\n",
            "\n",
            "        [[-1.1858, -1.1984,  2.1900,  ...,  0.3141, -0.2976, -0.9662],\n",
            "         [ 3.1516, -0.3418,  0.9400,  ...,  2.2662, -3.0799, -0.6063],\n",
            "         [-1.9556,  4.3700,  0.4663,  ...,  1.8101,  0.1262, -1.2754],\n",
            "         [ 0.0307, -0.7928,  1.3775,  ...,  0.6137,  1.6004, -2.0457]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.6415,  0.7224,  2.7702,  ...,  2.1515, -0.7594, -0.5652],\n",
            "         [ 2.2364, -0.3365, -0.2640,  ...,  1.4591, -3.8474,  2.1876],\n",
            "         [-2.0855,  2.0819,  1.6887,  ...,  2.4914, -1.6080, -1.1573],\n",
            "         [-0.1590,  0.8103,  1.7577,  ..., -0.4327,  0.5777, -2.0560]],\n",
            "\n",
            "        [[-1.6415,  0.7224,  2.7702,  ...,  2.1515, -0.7594, -0.5652],\n",
            "         [-1.5592, -2.3644, -2.1059,  ...,  0.6133, -3.7497, -1.3446],\n",
            "         [-2.0855,  2.0819,  1.6887,  ...,  2.4914, -1.6080, -1.1573],\n",
            "         [ 0.5131, -0.1374,  2.2446,  ..., -0.7197,  0.1920, -2.2625]],\n",
            "\n",
            "        [[-1.0378, -1.7946,  1.4663,  ..., -0.1046, -0.1507, -0.2322],\n",
            "         [ 1.0394,  0.9354,  2.0993,  ...,  2.3946, -3.9982,  0.2787],\n",
            "         [-2.2387,  0.3871, -0.4970,  ...,  0.1348, -0.9972, -0.9989],\n",
            "         [ 0.0786,  2.2688,  3.2343,  ...,  2.6633,  0.5390, -1.1132]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#init vectors for each words:\n",
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "    [\n",
        "        [0.1, 0.2, 0.3], # jim\n",
        "        [0.2, 0.3,0.4], # and\n",
        "        [0.3, 0.4, 0.5], #john\n",
        "        [0.4,0.5, 0.6], # are\n",
        "        [0.5, 0.6, 0.7], # brothers\n",
        "        [0.6,0.7,0.8], # likes\n",
        "        [0.7, 0.8, 0.9], #football\n",
        "        [0.8, 0.9, 1.0], #swimming\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "oZ0-jBFWY5iC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[0] #vector for \"jim\"\n",
        "attn_scores_jim = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  attn_scores_jim[i] = torch.dot(query, x_i)\n",
        "\n",
        "print(attn_scores_jim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL38Qj2YZ8nh",
        "outputId": "e1730075-a9f2-4953-fafa-a5fdcfa33c9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1400, 0.2000, 0.2600, 0.3200, 0.3800, 0.4400, 0.5000, 0.5600])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize attention value, make them sum up to 1.0\n",
        "attn_weights_jim = attn_scores_jim / attn_scores_jim.sum()\n",
        "print(attn_weights_jim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vWXdCH3a7Ak",
        "outputId": "043b2ab2-86db-4d6f-b047-c40687a15c61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0500, 0.0714, 0.0929, 0.1143, 0.1357, 0.1571, 0.1786, 0.2000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#softmax for normalization\n",
        "def softmax(x):\n",
        "  return (torch.exp(x) / torch.exp(x).sum()).numpy()\n",
        "\n",
        "attn_weights_jim_softmax = softmax(attn_scores_jim)\n",
        "print(attn_weights_jim_softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD51EsCJcRaj",
        "outputId": "0394ac14-a13d-4923-b482-c8967fe38d92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.10037188 0.10657853 0.11316898 0.12016696 0.12759766 0.13548787\n",
            " 0.14386596 0.15276214]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "dim = -1 means doing the softmax compution by the inner most dimension, since inputs is two dimension (row, column)\n",
        "the inner most dimension is column, therefore we are doing softmax on each row\n",
        "'''\n",
        "attn_weights_jim_softmax = torch.softmax(attn_scores_jim, dim = -1)\n",
        "print(attn_weights_jim_softmax)\n",
        "print(f\"sum is :{attn_weights_jim_softmax.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trJCyCMdc9O2",
        "outputId": "ca1717c4-bdd4-4341-d4d8-f216af640d55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1004, 0.1066, 0.1132, 0.1202, 0.1276, 0.1355, 0.1439, 0.1528])\n",
            "sum is :1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[0] #jim\n",
        "attn_jim_vector = torch.zeros(inputs.shape[-1])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  #sum up each vector with attention values\n",
        "  attn_jim_vector += attn_weights_jim_softmax[i] * x_i\n",
        "\n",
        "print(attn_jim_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFatCzHoeYCM",
        "outputId": "b4cb6376-4e4b-4542-bb37-28847e3bf914"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4814, 0.5814, 0.6814])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we have 8 words in the sentence, each word can compute attention value with other words which result in vector length of 8\n",
        "#since we have 8 words, then we have 8 vectors which has length of 8\n",
        "attn_scores = torch.empty(8, 8)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  for j, x_j in enumerate(inputs):\n",
        "    attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dEHMILofEeh",
        "outputId": "f503a149-a1d8-41fc-adba-b9ffcbc4d3e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1400, 0.2000, 0.2600, 0.3200, 0.3800, 0.4400, 0.5000, 0.5600],\n",
            "        [0.2000, 0.2900, 0.3800, 0.4700, 0.5600, 0.6500, 0.7400, 0.8300],\n",
            "        [0.2600, 0.3800, 0.5000, 0.6200, 0.7400, 0.8600, 0.9800, 1.1000],\n",
            "        [0.3200, 0.4700, 0.6200, 0.7700, 0.9200, 1.0700, 1.2200, 1.3700],\n",
            "        [0.3800, 0.5600, 0.7400, 0.9200, 1.1000, 1.2800, 1.4600, 1.6400],\n",
            "        [0.4400, 0.6500, 0.8600, 1.0700, 1.2800, 1.4900, 1.7000, 1.9100],\n",
            "        [0.5000, 0.7400, 0.9800, 1.2200, 1.4600, 1.7000, 1.9400, 2.1800],\n",
            "        [0.5600, 0.8300, 1.1000, 1.3700, 1.6400, 1.9100, 2.1800, 2.4500]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores, dim = -1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQLdHp3NgD6E",
        "outputId": "3ce13cf6-d383-4385-fdba-03b07095c0e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1004, 0.1066, 0.1132, 0.1202, 0.1276, 0.1355, 0.1439, 0.1528],\n",
            "        [0.0893, 0.0977, 0.1069, 0.1170, 0.1280, 0.1401, 0.1533, 0.1677],\n",
            "        [0.0791, 0.0892, 0.1006, 0.1134, 0.1278, 0.1441, 0.1625, 0.1832],\n",
            "        [0.0698, 0.0810, 0.0942, 0.1094, 0.1271, 0.1477, 0.1716, 0.1993],\n",
            "        [0.0612, 0.0733, 0.0878, 0.1051, 0.1258, 0.1506, 0.1803, 0.2159],\n",
            "        [0.0535, 0.0660, 0.0815, 0.1005, 0.1240, 0.1530, 0.1887, 0.2328],\n",
            "        [0.0466, 0.0592, 0.0753, 0.0957, 0.1217, 0.1547, 0.1967, 0.2500],\n",
            "        [0.0404, 0.0529, 0.0693, 0.0908, 0.1190, 0.1559, 0.2042, 0.2675]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_adjusted_vecs = attn_weights @ inputs\n",
        "print(all_adjusted_vecs)"
      ],
      "metadata": {
        "id": "vsurbCZfgh2d",
        "outputId": "e3eaafcb-4d85-4179-e741-f5888c383f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4814, 0.5814, 0.6814],\n",
            "        [0.4968, 0.5968, 0.6968],\n",
            "        [0.5120, 0.6120, 0.7120],\n",
            "        [0.5269, 0.6269, 0.7269],\n",
            "        [0.5413, 0.6413, 0.7413],\n",
            "        [0.5553, 0.6553, 0.7553],\n",
            "        [0.5688, 0.6688, 0.7688],\n",
            "        [0.5817, 0.6817, 0.7817]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize trainable matries of W_q, W_k, W_v\n",
        "d_in = 3\n",
        "d_out = 2\n",
        "torch.manual_seed(123)\n",
        "#requires_grad = False tell torch we will not going to train the matrix for now\n",
        "W_q = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_k = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_v = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "\n",
        "print(f\"W_q: {W_q}\\n W_k: {W_k}, W_v: {W_v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPc1DQjvOVui",
        "outputId": "b0d6da3d-55dc-4b8b-9321-5824c802386a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_q: Parameter containing:\n",
            "tensor([[0.2961, 0.5166],\n",
            "        [0.2517, 0.6886],\n",
            "        [0.0740, 0.8665]])\n",
            " W_k: Parameter containing:\n",
            "tensor([[0.1366, 0.1025],\n",
            "        [0.1841, 0.7264],\n",
            "        [0.3153, 0.6871]]), W_v: Parameter containing:\n",
            "tensor([[0.0756, 0.1966],\n",
            "        [0.3164, 0.4017],\n",
            "        [0.1186, 0.8274]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new word vector for jim by V_jim @ W_q\n",
        "V_jim = inputs[0]\n",
        "V_jim_new = V_jim @ W_q\n",
        "print(f\"new word vector for word 'jim' is :{V_jim_new}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSjunhUjPgkh",
        "outputId": "2e3f4dea-61d8-423c-8047-d4d8a53716bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new word vector for word 'jim' is :tensor([0.1021, 0.4493])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#multiply vectors of words from the sentence with W_k, W_v\n",
        "keys = inputs @ W_k\n",
        "values = inputs @ W_v\n",
        "print(f\"shape of keys: {keys.shape}\")\n",
        "print(f\"shape of values: {values.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv1GXCoFQlN9",
        "outputId": "d89b9114-1b64-416d-a7a3-a740dd67b25b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of keys: torch.Size([8, 2])\n",
            "shape of values: torch.Size([8, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#keys.T has shape (2, 8), the following multiply get (1, 8) which is a vector with length of 8,\n",
        "#each value in the result is attention scope for word jim\n",
        "attn_scores_jim = V_jim_new @ keys.T\n",
        "print(f\"attetion scopres for word jim: {attn_scores_jim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXE9qpykRtkE",
        "outputId": "ffed4fc1-a45f-466b-cff7-7b829878c6e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attetion scopres for word jim: tensor([0.1773, 0.2519, 0.3265, 0.4012, 0.4758, 0.5504, 0.6250, 0.6996])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "why need to divide each value with square root of the dimension value of W_k? This is some kind of art, by doing this can make the trainning process more\n",
        "efficient, there are lots of \"non-AI\" in the process of designing AI, the purpose of it is to avoid small gradients which will greatly slow down the progress of traning\n",
        "'''\n",
        "\n",
        "dimension_w_k = keys.shape[-1] #2\n",
        "attn_weights_jim = torch.softmax(attn_scores_jim / dimension_w_k ** 0.5, dim = -1)\n",
        "print(f\"attention scores of word 'jim' after normalization: {attn_weights_jim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9yO_l_RSyvt",
        "outputId": "c0938f7b-a419-4bfc-d329-b4446af0c940"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention scores of word 'jim' after normalization: tensor([0.1032, 0.1088, 0.1146, 0.1209, 0.1274, 0.1343, 0.1416, 0.1493])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new word vector of jim\n",
        "word_vec_jim = attn_weights_jim @ values\n",
        "print(f\"word vector for word 'jim': {word_vec_jim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4LNnQSaVyrn",
        "outputId": "77bb1c84-b17a-43f2-cc7b-27071b655282"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word vector for word 'jim': tensor([0.2992, 0.8866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Three matries are bollowed from databases, the query used to indicate what you are looking for,\n",
        "key used to confine the info in given scope, and value is the details in the given scope. For example\n",
        "you are going to find some thing to watch, then the query can be \"movie\", the selections for\n",
        "key can be \"action, hollow, love, documentary\", if the key is \"action\", then the value can be\n",
        "list of names of action movies\n",
        "'''\n",
        "import torch.nn as nn\n",
        "class SelfAttentionV1(nn.Module):\n",
        "  def __init__(self, input_vec_length, output_vec_lenth):\n",
        "    super().__init__()\n",
        "    #randomize the value for three matries\n",
        "    self.W_query = nn.Parameter(torch.rand(input_vec_length, output_vec_lenth))\n",
        "    self.W_key = nn.Parameter(torch.rand(input_vec_length, output_vec_lenth))\n",
        "    self.W_value = nn.Parameter(torch.rand(input_vec_length, output_vec_lenth))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    '''\n",
        "    inputs are words for the sentences, each word in the sentence will go through the process\n",
        "    above, then each word can be the query word\n",
        "    '''\n",
        "    keys = inputs @ self.W_key\n",
        "    values = inputs @ self.W_value\n",
        "    query = inputs @ self.W_query\n",
        "    attn_scores = query @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
        "    new_word_vecs = attn_weights @ values\n",
        "    return new_word_vecs"
      ],
      "metadata": {
        "id": "Bm_4i93rV1FH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "attn_process = SelfAttentionV1(3, 2)\n",
        "attn_process.forward(inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wscwlYTFUHw0",
        "outputId": "18cff9e7-36fc-43b9-a8cb-644f37a0b9b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2992, 0.8866],\n",
              "        [0.3058, 0.9051],\n",
              "        [0.3124, 0.9233],\n",
              "        [0.3188, 0.9412],\n",
              "        [0.3251, 0.9588],\n",
              "        [0.3312, 0.9760],\n",
              "        [0.3372, 0.9927],\n",
              "        [0.3430, 1.0089]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "'''\n",
        "number for x is 5, and number for y is 3\n",
        "'''\n",
        "linear_layer = nn.Linear(in_features = 5, out_features = 3, bias = True)\n",
        "print(f\"Matrix A is : \", linear_layer.weight)\n",
        "print(f\"B is : \", linear_layer.bias)\n",
        "\n",
        "#[x1,...x5]\n",
        "x = torch.randn(1, 5)\n",
        "print(f\"x is : {x}\")\n",
        "print(f\"y is : {linear_layer(x)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOB9X1a9SdOx",
        "outputId": "0cb6ff65-9867-44ff-f1aa-a40274a8aab8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A is :  Parameter containing:\n",
            "tensor([[ 0.3620,  0.1702, -0.2314, -0.2344, -0.1186],\n",
            "        [-0.3954,  0.4148, -0.0920, -0.0579, -0.4362],\n",
            "        [ 0.1407,  0.2512, -0.0271,  0.1622,  0.1007]], requires_grad=True)\n",
            "B is :  Parameter containing:\n",
            "tensor([-0.0858,  0.0015,  0.0408], requires_grad=True)\n",
            "x is : tensor([[-0.4950, -1.3638, -1.2959,  0.5380, -0.3010]])\n",
            "y is : tensor([[-0.2877, -0.1490, -0.2794]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "class SelfAttentionV2(nn.Module):\n",
        "  def __init__(self, input_vec_length, output_vec_lenth, bias = False):\n",
        "    super().__init__()\n",
        "    #randomize the value for three matries\n",
        "    self.W_query = nn.Linear(in_features = input_vec_length, out_features = output_vec_lenth, bias = bias)\n",
        "    self.W_key = nn.Linear(in_features = input_vec_length, out_features = output_vec_lenth, bias = bias)\n",
        "    self.W_value = nn.Linear(in_features = input_vec_length, out_features = output_vec_lenth, bias = bias)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    '''\n",
        "    inputs are words for the sentences, each word in the sentence will go through the process\n",
        "    above, then each word can be the query word\n",
        "    '''\n",
        "\n",
        "    keys = self.W_key(inputs)\n",
        "    values = self.W_value(inputs)\n",
        "    query = self.W_query(inputs)\n",
        "    attn_scores = query @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
        "    new_word_vecs = attn_weights @ values\n",
        "    return new_word_vecs"
      ],
      "metadata": {
        "id": "YLxgauJpUv6S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "attn_process = SelfAttentionV2(3, 2)\n",
        "attn_process.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR0Ky7FEVijV",
        "outputId": "e8589302-b83b-4e9c-c345-4cf57a541cf6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5566, -0.0485],\n",
              "        [-0.5592, -0.0489],\n",
              "        [-0.5618, -0.0494],\n",
              "        [-0.5644, -0.0498],\n",
              "        [-0.5670, -0.0502],\n",
              "        [-0.5696, -0.0507],\n",
              "        [-0.5722, -0.0511],\n",
              "        [-0.5748, -0.0515]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}